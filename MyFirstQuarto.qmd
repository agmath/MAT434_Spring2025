---
title: My First Quarto Document
author: 
  - name: Adam Gilbert
    email: a.gilbert1@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
format: html
date: 9/15/2024
date-modified: today
date-format: long
theme: flatly
toc: true
---

## Working with Data

### Loading Data

```{r}
#| message: false
#| code-fold: true

library(tidyverse)
library(tidymodels)
library(skimr)

hits <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/battedballs.csv")
parks <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/park_dimensions.csv")
```

## Exploring Our Data

```{r}
#head(hits)

hits %>% 
  head()
```

```{r}
parks %>%
  head()
```

### Joining the Data

```{r}
hits <- hits %>%
  left_join(parks, by = c("park"  = "park"))
```

We joined the `hits` and `parks` data together, to obtain a full data set with `r nrow(hits)` rows and `r ncol(hits)` columns.

### Initial explorations

View the first 6 rows of observations

```{r}
hits %>%
  head()
```

See the "type" (according to R) of each variable in the data set

```{r}
hits %>%
  glimpse()
```

Skimming the data set to get a surface level analysis. This is useful for identifying data issues, like missing values or for identifying extreme class imbalances. For example, only abotu 5.5% of observations resulted in home runs while the remaining 94.5% were not home runs.

```{r}
hits %>%
  skim()
```

### Split into training and test data

Remember that we need some data for us (and our eventual models) to *learn* from and then another set of observations to assess our model performance against. The code below splits our data into a *training* pile (the data we can use and learn from) and a *testing* pile (the data we'll hide from ourselves and our models until the very end of our project). The `set.seed()` function ensures that we obtain the same *training* and *test* data every time we run this notebook. Be sure to set a seed any time you are splitting your data (or doing anything else that involves randomness).

```{r}
set.seed(434)
data_splits <- initial_split(hits, 0.85, strata = is_home_run)

train <- training(data_splits)
test <- testing(data_splits)
```

## Exploratory Data Analysis

We want to know how and why home runs happen. Can we predict what types of scenarios are most likely to end in a home run? 

### Sometimes Useful Functionality

The following functions: `filter()` and `select()` are not directly useful here. They allow us to view, or work with, a subset of our available data. The `filter()` function returns only rows satisfying the criteria we dictate, while the `select()` function returns only the columns we request.

Filtering rows

```{r}
train %>%
  filter(is_home_run == 1)

train %>%
  filter(launch_angle > 45)

train %>%
  filter(str_detect(NAME, "Fenway"))
```

Selecting just a few columns

```{r}
train %>%
  select(launch_speed, launch_angle, is_home_run)
```

### Feature Engineering (Creating New Variables)

Building new variables from old ones (*Feature Engineering*) can be done with the `mutate()` function. This function either adds a new column to your data set or edits an existing column. Inside of `mutate()` the text to the left of the equal sign (`=`) is the column name and the expression to the right of the equal sign (`=`) indicates how the values under this column will be computed.

```{r}
train %>%
  mutate(fast_pitch = ifelse(pitch_mph > 100, "yes", "no"))
```

Note that the new variable is only added temporarily. We'd need to store the result of the mutation in order to retain access to the new variable.

```{r}
train_with_fast_pitch <- train %>%
  mutate(fast_pitch = ifelse(pitch_mph > 100, "yes", "no"))
```

### Summary statistics

Home runs...

```{r}
train %>%
  count(is_home_run) %>%
  mutate(prop = 100*n/sum(n))
```

```{r}
train %>%
  summarize(pct_hr = 100*mean(is_home_run))
```

Summarizing Launch Angle...

```{r}
train %>%
  filter(!is.na(launch_angle)) %>%
  summarize(
    min_angle = min(launch_angle),
    mean_angle = mean(launch_angle),
    median_angle = median(launch_angle),
    max_angle = max(launch_angle),
    sd_angle = sd(launch_angle)
  )
```

#### Grouped Summaries

```{r}
train %>%
  group_by(NAME, is_home_run) %>%
  filter(!is.na(launch_angle)) %>%
  summarize(
    min_angle = min(launch_angle),
    mean_angle = mean(launch_angle),
    median_angle = median(launch_angle),
    max_angle = max(launch_angle),
    sd_angle = sd(launch_angle)
  )
```